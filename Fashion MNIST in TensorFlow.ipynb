{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnyTxjK_GbOD"
   },
   "source": [
    "# Using TensorFlow for Classification\n",
    "\n",
    "Adapted from https://www.coursera.org/learn/introduction-tensorflow Week 1 Notebook.\n",
    "\n",
    "Let's take a look at a scenario where we can recognize different items of clothing (Fashion MNIST), trained from a dataset containing 10 different types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H41FYgtlHPjW"
   },
   "source": [
    "## Start Coding\n",
    "\n",
    "Let's start with our import of TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "q3KzJyjv3rnA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_n1U5do3u_F"
   },
   "source": [
    "The Fashion MNIST data is available directly in the tf.keras datasets API. You load it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PmxkHFpt31bM"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuoLQQBT4E-_"
   },
   "source": [
    "Calling load_data on this object will give you two sets of two lists, these will be the training and testing values for the graphics that contain the clothing items and their labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BTdRgExe4TRB"
   },
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_images.shape, training_labels.shape, test_images.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rw395ROx4f5Q"
   },
   "source": [
    "What does these values look like? Let's print a training image, and a training label to see...Experiment with different indices in the array. For example, also take a look at index 42...that's a a different boot than the one at index 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "FPc9d3gJ3jWF"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=200)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# change the index here (between 0 to 59999) to change the item\n",
    "index = 0\n",
    "\n",
    "plt.imshow(training_images[index])\n",
    "plt.show()\n",
    "labels = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "print(f'Class: {labels[training_labels[index]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[[0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.         0.         0.05098039 0.28627451\n",
      "  0.         0.         0.00392157 0.01568627 0.         0.         0.         0.         0.00392157 0.00392157 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.01176471 0.         0.14117647 0.53333333 0.49803922\n",
      "  0.24313725 0.21176471 0.         0.         0.         0.00392157 0.01176471 0.01568627 0.         0.         0.01176471]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.02352941 0.         0.4        0.8        0.69019608\n",
      "  0.5254902  0.56470588 0.48235294 0.09019608 0.         0.         0.         0.         0.04705882 0.03921569 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.60784314 0.9254902  0.81176471\n",
      "  0.69803922 0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608 0.30196078 0.50980392 0.28235294 0.05882353]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.         0.27058824 0.81176471 0.8745098  0.85490196\n",
      "  0.84705882 0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902 0.55294118 0.34509804 0.6745098  0.25882353]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.00392157 0.00392157 0.         0.78431373 0.90980392 0.90980392 0.91372549\n",
      "  0.89803922 0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922 0.48235294 0.76862745 0.89803922 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.71764706 0.88235294 0.84705882 0.8745098\n",
      "  0.89411765 0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667 0.8745098  0.96078431 0.67843137 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.75686275 0.89411765 0.85490196 0.83529412\n",
      "  0.77647059 0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098  0.8627451  0.95294118 0.79215686 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.01176471 0.         0.04705882 0.85882353 0.8627451  0.83137255 0.85490196\n",
      "  0.75294118 0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255 0.88627451 0.77254902 0.81960784 0.20392157]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.02352941 0.         0.38823529 0.95686275 0.87058824 0.8627451  0.85490196\n",
      "  0.79607843 0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451  0.96078431 0.46666667 0.65490196 0.21960784]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.01568627 0.         0.         0.21568627 0.9254902  0.89411765 0.90196078 0.89411765\n",
      "  0.94117647 0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039 0.85098039 0.81960784 0.36078431 0.        ]\n",
      " [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098 0.00784314 0.         0.         0.         0.         0.         0.92941176 0.88627451 0.85098039 0.8745098  0.87058824\n",
      "  0.85882353 0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725 0.85490196 1.         0.30196078 0.        ]\n",
      " [0.         0.01176471 0.         0.         0.         0.         0.         0.         0.         0.24313725 0.56862745 0.8        0.89411765 0.81176471 0.83529412 0.86666667 0.85490196\n",
      "  0.81568627 0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725 0.87843137 0.95686275 0.62352941 0.        ]\n",
      " [0.         0.         0.         0.         0.07058824 0.17254902 0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824 0.85098039 0.88627451 0.78431373 0.80392157 0.82745098\n",
      "  0.90196078 0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902 0.91372549 0.93333333 0.84313725 0.        ]\n",
      " [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667 0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784 0.78431373 0.62352941 0.96078431 0.75686275 0.80784314\n",
      "  0.8745098  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098 0.8627451  0.90980392 0.96470588 0.        ]\n",
      " [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098 0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451  0.94117647 0.31372549 0.58823529 1.         0.89803922\n",
      "  0.86666667 0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784 0.87058824 0.89411765 0.88235294 0.        ]\n",
      " [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922 0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725 0.85098039 0.94509804 0.25490196 0.28627451 0.41568627\n",
      "  0.45882353 0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098  0.8745098  0.87843137 0.89803922 0.11372549]\n",
      " [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157 0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314 0.77647059 0.83529412 0.94117647 0.76470588 0.89019608\n",
      "  0.96078431 0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824 0.8627451  0.86666667 0.90196078 0.2627451 ]\n",
      " [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902 0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569 0.85882353 0.86666667 0.8627451  0.9254902  0.88235294\n",
      "  0.84705882 0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098  0.70980392 0.80392157 0.80784314 0.45098039]\n",
      " [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824 0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471 0.82745098 0.82352941 0.78431373 0.76862745 0.76078431\n",
      "  0.74901961 0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471 0.65490196 0.69411765 0.82352941 0.36078431]\n",
      " [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961 0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549  0.74117647 0.7372549  0.75686275 0.77647059 0.8\n",
      "  0.81960784 0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431 0.75294118 0.84705882 0.66666667 0.        ]\n",
      " [0.00784314 0.         0.         0.         0.25882353 0.78431373 0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118 0.95686275 0.86666667 0.8627451  0.75686275 0.74901961\n",
      "  0.70196078 0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353 0.38823529 0.22745098 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431 0.1372549  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(training_labels[0])\n",
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cbrdH225_nH"
   },
   "source": [
    "You'll notice that all of the values in the number are between 0 and 255. If we are training a neural network, for various reasons it's easier if we treat all values as between 0 and 1, a process called '**normalizing**'...and fortunately in Python it's easy to normalize a list like this without looping. You do it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kRH19pWs6ZDn"
   },
   "outputs": [],
   "source": [
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.         0.         0.05098039 0.28627451\n",
      "  0.         0.         0.00392157 0.01568627 0.         0.         0.         0.         0.00392157 0.00392157 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.01176471 0.         0.14117647 0.53333333 0.49803922\n",
      "  0.24313725 0.21176471 0.         0.         0.         0.00392157 0.01176471 0.01568627 0.         0.         0.01176471]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.02352941 0.         0.4        0.8        0.69019608\n",
      "  0.5254902  0.56470588 0.48235294 0.09019608 0.         0.         0.         0.         0.04705882 0.03921569 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.60784314 0.9254902  0.81176471\n",
      "  0.69803922 0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608 0.30196078 0.50980392 0.28235294 0.05882353]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.         0.27058824 0.81176471 0.8745098  0.85490196\n",
      "  0.84705882 0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902 0.55294118 0.34509804 0.6745098  0.25882353]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.00392157 0.00392157 0.         0.78431373 0.90980392 0.90980392 0.91372549\n",
      "  0.89803922 0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922 0.48235294 0.76862745 0.89803922 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.71764706 0.88235294 0.84705882 0.8745098\n",
      "  0.89411765 0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667 0.8745098  0.96078431 0.67843137 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.75686275 0.89411765 0.85490196 0.83529412\n",
      "  0.77647059 0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098  0.8627451  0.95294118 0.79215686 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.01176471 0.         0.04705882 0.85882353 0.8627451  0.83137255 0.85490196\n",
      "  0.75294118 0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255 0.88627451 0.77254902 0.81960784 0.20392157]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.02352941 0.         0.38823529 0.95686275 0.87058824 0.8627451  0.85490196\n",
      "  0.79607843 0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451  0.96078431 0.46666667 0.65490196 0.21960784]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.01568627 0.         0.         0.21568627 0.9254902  0.89411765 0.90196078 0.89411765\n",
      "  0.94117647 0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039 0.85098039 0.81960784 0.36078431 0.        ]\n",
      " [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098 0.00784314 0.         0.         0.         0.         0.         0.92941176 0.88627451 0.85098039 0.8745098  0.87058824\n",
      "  0.85882353 0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725 0.85490196 1.         0.30196078 0.        ]\n",
      " [0.         0.01176471 0.         0.         0.         0.         0.         0.         0.         0.24313725 0.56862745 0.8        0.89411765 0.81176471 0.83529412 0.86666667 0.85490196\n",
      "  0.81568627 0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725 0.87843137 0.95686275 0.62352941 0.        ]\n",
      " [0.         0.         0.         0.         0.07058824 0.17254902 0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824 0.85098039 0.88627451 0.78431373 0.80392157 0.82745098\n",
      "  0.90196078 0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902 0.91372549 0.93333333 0.84313725 0.        ]\n",
      " [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667 0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784 0.78431373 0.62352941 0.96078431 0.75686275 0.80784314\n",
      "  0.8745098  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098 0.8627451  0.90980392 0.96470588 0.        ]\n",
      " [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098 0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451  0.94117647 0.31372549 0.58823529 1.         0.89803922\n",
      "  0.86666667 0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784 0.87058824 0.89411765 0.88235294 0.        ]\n",
      " [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922 0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725 0.85098039 0.94509804 0.25490196 0.28627451 0.41568627\n",
      "  0.45882353 0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098  0.8745098  0.87843137 0.89803922 0.11372549]\n",
      " [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157 0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314 0.77647059 0.83529412 0.94117647 0.76470588 0.89019608\n",
      "  0.96078431 0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824 0.8627451  0.86666667 0.90196078 0.2627451 ]\n",
      " [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902 0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569 0.85882353 0.86666667 0.8627451  0.9254902  0.88235294\n",
      "  0.84705882 0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098  0.70980392 0.80392157 0.80784314 0.45098039]\n",
      " [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824 0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471 0.82745098 0.82352941 0.78431373 0.76862745 0.76078431\n",
      "  0.74901961 0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471 0.65490196 0.69411765 0.82352941 0.36078431]\n",
      " [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961 0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549  0.74117647 0.7372549  0.75686275 0.77647059 0.8\n",
      "  0.81960784 0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431 0.75294118 0.84705882 0.66666667 0.        ]\n",
      " [0.00784314 0.         0.         0.         0.25882353 0.78431373 0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118 0.95686275 0.86666667 0.8627451  0.75686275 0.74901961\n",
      "  0.70196078 0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353 0.38823529 0.22745098 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431 0.1372549  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DkO0As46lRn"
   },
   "source": [
    "Now you might be wondering why there are 2 sets...training and testing -- remember we spoke about this in the intro? The idea is to have 1 set of data for training, and then another set of data...that the model hasn't yet seen...to see how good it would be at classifying values. After all, when you're done, you're going to want to try it out with data that it hadn't previously seen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIn7S9gf62ie"
   },
   "source": [
    "Let's now design the model. There's quite a few new concepts here, but don't worry, you'll get the hang of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "7mAyndG3kVlK"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [tf.keras.layers.Input(shape = (28,28)),\n",
    "    tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_24 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lUcWaiX7MFj"
   },
   "source": [
    "**Sequential**: That defines a SEQUENCE of layers in the neural network\n",
    "\n",
    "**Flatten**: Remember earlier where our images were a square, when you printed them out? Flatten just takes that square and turns it into a 1 dimensional set.\n",
    "\n",
    "**Dense**: Adds a layer of neurons\n",
    "\n",
    "Each layer of neurons need an **activation function** to tell them what to do. There's lots of options, but just use these for now. \n",
    "\n",
    "**Relu** effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\n",
    "\n",
    "**Softmax** takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8vbMCqb9Mh6"
   },
   "source": [
    "The next thing to do, now the model is defined, is to actually build it. You do this by compiling it with an optimizer and loss function as before -- and then you train it by calling **model.fit ** asking it to fit your training data to your training labels -- i.e. have it figure out the relationship between the training data and its actual labels, so in future if you have data that looks like the training data, then it can make a prediction for what that data would look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "BLMdl9aP8nQ0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 1s 786us/step - loss: 0.5055 - accuracy: 0.8223 - val_loss: 0.4254 - val_accuracy: 0.8482\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 1s 733us/step - loss: 0.3774 - accuracy: 0.8660 - val_loss: 0.4239 - val_accuracy: 0.8467\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 1s 748us/step - loss: 0.3399 - accuracy: 0.8749 - val_loss: 0.3564 - val_accuracy: 0.8728\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 1s 768us/step - loss: 0.3161 - accuracy: 0.8829 - val_loss: 0.3538 - val_accuracy: 0.8658\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 1s 777us/step - loss: 0.2950 - accuracy: 0.8902 - val_loss: 0.3467 - val_accuracy: 0.8768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcca6f12610>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images, training_labels, validation_split = 0.1, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JJMsvSB-1UY"
   },
   "source": [
    "Once it's done training -- you should see an accuracy value at the end of the final epoch. It might look something like 0.9098. This tells you that your neural network is about 91% accurate in classifying the training data. I.E., it figured out a pattern match between the image and the labels that worked 91% of the time. Not great, but not bad considering it was only trained for 5 epochs and done quite quickly.\n",
    "\n",
    "But how would it work with unseen data? That's why we have the test images. We can call model.evaluate, and pass in the two sets, and it will report back the loss for each. Let's give it a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "WzlqsEzX9s5P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 545us/step - loss: 0.3436 - accuracy: 0.8751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3436215817928314, 0.8751000165939331]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tki-Aro_Uax"
   },
   "source": [
    "For me, that returned a accuracy of about .875, which means it was about 88% accurate. As expected it probably would not do as well with *unseen* data as it did with data it was trained on!  As you go through this course, you'll look at ways to improve this. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Functional API\n",
    "We can also define the model in a functional form, for greater flexibility.\n",
    "This is exactly the same as the earlier model.\n",
    "Uncomment the cell to run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tf.keras.layers.Input(shape = (28,28))\n",
    "\n",
    "# x = tf.keras.layers.Flatten()(inputs)\n",
    "# x = tf.keras.layers.Dense(128, activation = tf.nn.relu)(x)\n",
    "# outputs = tf.keras.layers.Dense(10, activation = tf.nn.softmax)(x)\n",
    "\n",
    "# model = tf.keras.Model(inputs = inputs, outputs = outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htldZNWcIPSN"
   },
   "source": [
    "# Exploration Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rquQqIx4AaGR"
   },
   "source": [
    "###Exercise 1:\n",
    "For this first exercise run the below code: It creates a set of classifications for each of the test images, and then prints the first entry in the classifications. The output, after you run it is a list of numbers. Why do you think this is, and what do those numbers represent? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "RyEIki0z_hAD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07315972 0.04128658 0.1259507  0.06062017 0.09420821 0.04218186 0.08253103 0.17838682 0.1160433  0.1856316 ]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdzqbQhRArzm"
   },
   "source": [
    "Hint: try running print(test_labels[0]) -- and you'll get a 9. Does that help you understand why this list looks the way it does? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "WnBGOrMiA1n5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUs7eqr7uSvs"
   },
   "source": [
    "### What does this list represent?\n",
    "\n",
    "\n",
    "1.   It's 10 random meaningless values\n",
    "2.   It's the first 10 classifications that the computer made\n",
    "3.   It's the probability that this item is each of the 10 classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAbr92RTA67u"
   },
   "source": [
    "#### Answer: \n",
    "The correct answer is (3)\n",
    "\n",
    "The output of the model is a list of 10 numbers. These numbers are a probability that the value being classified is the corresponding value (https://github.com/zalandoresearch/fashion-mnist#labels), i.e. the first value in the list is the probability that the image is of a '0' (T-shirt/top), the next is a '1' (Trouser) etc. Notice that they are all VERY LOW probabilities.\n",
    "\n",
    "For the 9 (Ankle boot), the probability was in the 90's, i.e. the neural network is telling us that it's almost certainly a 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CD4kC6TBu-69"
   },
   "source": [
    "### How do you know that this list tells you that the item is an ankle boot?\n",
    "\n",
    "\n",
    "1.   There's not enough information to answer that question\n",
    "2.   The 10th element on the list is the biggest, and the ankle boot is labelled 9\n",
    "2.   The ankle boot is label 9, and there are 0->9 elements in the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-haLncrva5L"
   },
   "source": [
    "#### Answer\n",
    "The correct answer is (2). Both the list and the labels are 0 based, so the ankle boot having label 9 means that it is the 10th of the 10 classes. The list having the 10th element being the highest value means that the Neural Network has predicted that the item it is classifying is most likely an ankle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgQSIfDSOWv6"
   },
   "source": [
    "## Exercise 2: \n",
    "Let's now look at the layers in your model. Experiment with different values for the first dense layer. What different results do you get for loss, training time etc? Why do you think that's the case? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "GSZSwV5UObQP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4695 - accuracy: 0.8318\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3599 - accuracy: 0.8693\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3233 - accuracy: 0.8803\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2974 - accuracy: 0.8906\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2791 - accuracy: 0.8960\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3457 - accuracy: 0.8763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34567904472351074, 0.8762999773025513]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOOEnHZFv5cS"
   },
   "source": [
    "### Question 1. Increase to 1024 Neurons -- What's the impact?\n",
    "\n",
    "1. Training takes longer, but is more accurate\n",
    "2. Training takes longer, but no impact on accuracy\n",
    "3. Training takes the same time, but is more accurate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U73MUP2lwrI2"
   },
   "source": [
    "#### Answer\n",
    "The correct answer is (1) by adding more Neurons we have to do more calculations, slowing down the process, but in this case they have a good impact -- we do get more accurate. That doesn't mean it's always a case of 'more is better', you can hit the law of diminishing returns very quickly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtWxK16hQxLN"
   },
   "source": [
    "## Exercise 3: \n",
    "\n",
    "What would happen if you remove the Flatten() layer. Why do you think that's the case? \n",
    "\n",
    "You get an error about the shape of the data. It may seem vague right now, but it reinforces the rule of thumb that the first layer in your network should be the same shape as your data. Right now our data is 28x28 images, and 28 layers of 28 neurons would be infeasible, so it makes more sense to 'flatten' that 28,28 into a 784x1. Instead of wriitng all the code to handle that ourselves, we add the Flatten() layer at the begining, and when the arrays are loaded into the model later, they'll automatically be flattened for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "ExNxCwhcQ18S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 651us/step - loss: 0.4961 - accuracy: 0.8249\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 649us/step - loss: 0.3734 - accuracy: 0.8631\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 646us/step - loss: 0.3351 - accuracy: 0.8769\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 643us/step - loss: 0.3124 - accuracy: 0.8842\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 656us/step - loss: 0.2936 - accuracy: 0.8912\n",
      "313/313 [==============================] - 0s 538us/step - loss: 0.3441 - accuracy: 0.8767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3440624177455902, 0.8766999840736389]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([#tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "training_images = training_images.reshape(len(training_images), -1)\n",
    "test_images = test_images.reshape(len(test_images), -1)\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqoCR-ieSGDg"
   },
   "source": [
    "## Exercise 4: \n",
    "\n",
    "Consider the final (output) layers. Why are there 10 of them? What would happen if you had a different amount than 10? For example, try training the network with 5\n",
    "\n",
    "You get an error as soon as it finds an unexpected value. Another rule of thumb -- the number of neurons in the last layer should match the number of classes you are classifying for. In this case it's the digits 0-9, so there are 10 of them, hence you should have 10 neurons in your final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "MMckVntcSPvo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Received a label value of 9 which is outside the valid range of [0, 6).  Label values: 1 3 0 9 3 5 1 1 3 4 2 7 4 7 7 2 7 7 6 6 6 2 7 4 2 7 2 4 8 9 1 0\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-90-bc953f839d08>:18) ]] [Op:__inference_train_function_379701]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-bc953f839d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m               loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Received a label value of 9 which is outside the valid range of [0, 6).  Label values: 1 3 0 9 3 5 1 1 3 4 2 7 4 7 7 2 7 7 6 6 6 2 7 4 2 7 2 4 8 9 1 0\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-90-bc953f839d08>:18) ]] [Op:__inference_train_function_379701]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(6, activation=tf.nn.softmax)]) #This needs to be 10\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0lF5MuvSuZF"
   },
   "source": [
    "## Exercise 5: \n",
    "\n",
    "Consider the effects of additional layers in the network. What will happen if you add another layer between the one with 128 and the final layer with 10. \n",
    "\n",
    "Ans: There isn't a significant impact -- because this is relatively simple data. For far more complex data (including color images to be classified as flowers that you'll see in the next lesson), extra layers are often necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "b1YPa6UhS8Es"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 713us/step - loss: 0.4954 - accuracy: 0.8246\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 714us/step - loss: 0.3685 - accuracy: 0.8660\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 715us/step - loss: 0.3308 - accuracy: 0.8788\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 703us/step - loss: 0.3086 - accuracy: 0.8861\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 708us/step - loss: 0.2906 - accuracy: 0.8917\n",
      "313/313 [==============================] - 0s 562us/step - loss: 0.3287 - accuracy: 0.8821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3287460207939148, 0.882099986076355]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bql9fyaNUSFy"
   },
   "source": [
    "# Exercise 6: \n",
    "\n",
    "Consider the impact of training for more or less epochs. Why do you think that would be the case? \n",
    "\n",
    "Try 15 epochs -- you'll probably get a model with a much better loss than the one with 5\n",
    "Try 30 epochs -- you might see the loss value stops decreasing, and sometimes increases. This is a side effect of something called 'overfitting' which you can learn about [somewhere] and it's something you need to keep an eye out for when training neural networks. There's no point in wasting your time training if you aren't improving your loss, right! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "uE3esj9BURQe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 1s 653us/step - loss: 0.4976 - accuracy: 0.8260\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 1s 646us/step - loss: 0.3765 - accuracy: 0.8640\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 1s 653us/step - loss: 0.3371 - accuracy: 0.8771\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 1s 665us/step - loss: 0.3124 - accuracy: 0.8852\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 1s 671us/step - loss: 0.2930 - accuracy: 0.8916\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 1s 687us/step - loss: 0.2798 - accuracy: 0.8967\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 1s 684us/step - loss: 0.2676 - accuracy: 0.9010\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 1s 690us/step - loss: 0.2573 - accuracy: 0.9040\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 1s 686us/step - loss: 0.2465 - accuracy: 0.9089\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 1s 689us/step - loss: 0.2395 - accuracy: 0.9102\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 1s 687us/step - loss: 0.2315 - accuracy: 0.9133\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 1s 684us/step - loss: 0.2231 - accuracy: 0.9166\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 1s 688us/step - loss: 0.2174 - accuracy: 0.9196\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 1s 693us/step - loss: 0.2107 - accuracy: 0.9221\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 1s 697us/step - loss: 0.2043 - accuracy: 0.9227\n",
      "313/313 [==============================] - 0s 566us/step - loss: 0.3447 - accuracy: 0.8847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3446747660636902, 0.8847000002861023]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=15)\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HS3vVkOgCDGZ"
   },
   "source": [
    "# Exercise 7: \n",
    "\n",
    "Before you trained, you normalized the data, going from values that were 0-255 to values that were 0-1. What would be the impact of removing that? Here's the complete code to give it a try. Why do you think you get different results? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "JDqNAqrpCNg0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 694us/step - loss: 3.1243 - accuracy: 0.6851\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 692us/step - loss: 0.7242 - accuracy: 0.7527\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 688us/step - loss: 0.5972 - accuracy: 0.7888\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 690us/step - loss: 0.5405 - accuracy: 0.8108\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 686us/step - loss: 0.5111 - accuracy: 0.8237\n",
      "313/313 [==============================] - 0s 547us/step - loss: 0.5071 - accuracy: 0.8299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5071320533752441, 0.8299000263214111]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7W2PT66ZBHQ"
   },
   "source": [
    "# Exercise 8: \n",
    "\n",
    "Earlier when you trained for extra epochs you had an issue where your loss might change. It might have taken a bit of time for you to wait for the training to do that, and you might have thought 'wouldn't it be nice if I could stop the training when I reach a desired value?' -- i.e. 95% accuracy might be enough for you, and if you reach that after 3 epochs, why sit around waiting for it to finish a lot more epochs....So how would you fix that? Like any other program...you have callbacks! Let's see them in action..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to https://www.tensorflow.org/guide/keras/custom_callback for custom callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "pkaEHHgqZbYv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 661us/step - loss: 0.4935 - accuracy: 0.8268\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 665us/step - loss: 0.3724 - accuracy: 0.8651\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 672us/step - loss: 0.3340 - accuracy: 0.8786\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 678us/step - loss: 0.3099 - accuracy: 0.8863\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 685us/step - loss: 0.2913 - accuracy: 0.8917\n",
      "313/313 [==============================] - 0s 542us/step - loss: 0.3512 - accuracy: 0.8761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3512040078639984, 0.8761000037193298]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('loss')<0.4):\n",
    "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Course 1 - Part 4 - Lesson 2 - Notebook.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
